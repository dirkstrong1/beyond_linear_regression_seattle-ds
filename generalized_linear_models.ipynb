{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/learn-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "//anaconda3/envs/learn-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 216, got 192\n",
      "  return f(*args, **kwds)\n",
      "//anaconda3/envs/learn-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regressions have limitations.\n",
    "\n",
    "As it stands, the algorithm could generate a prediction *anywhere on the real number line*. This *may* be realistic, like if I'm predicting national surpluses/debts.\n",
    "\n",
    "But what if I'm predicting values of a variable that doesn't take, say, negative values, like temperature in Kelvin?\n",
    "\n",
    "What if I'm predicting values of a variable that takes only integer values, like the number of mouseclicks on my killer ds blog per minute?\n",
    "\n",
    "What if I'm predicting probabilities? Or something Boolean / Bernoullian?\n",
    "\n",
    "What if the shape of my errors changes as a function of the dependent variable?\n",
    "\n",
    "Am I stuck using linear regression? There's got to be a better way!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy now is to *generalize* the notion of linear regression; regression will become a special case. In particular, we'll keep the idea of the regression best-fit line, but now **we'll allow the model to be constructed from the dependent variable through some (non-trivial) function of the linear predictor**. This function is standardly called the **link function**.\n",
    "\n",
    "Let's say we've constructed our best-fit line, i.e. our linear predictor, $\\hat{L} = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$.\n",
    "\n",
    "And now imagine applying a link function ... Check out Wikipedia's page on [Generalized Linear Models](https://en.wikipedia.org/wiki/Generalized_linear_model)!\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "Consider the following transformation: <br/>\n",
    "$\\large\\hat{y} = \\Large\\frac{1}{1 + e^{-\\hat{L}}} \\large= \\Large\\frac{1}{1 + e^{-(\\beta_0 + ... + \\beta_nx_n)}}$. This is called the **sigmoid function**.\n",
    "\n",
    "We're imagining that $\\hat{L}$ can take any values between $-\\infty$ and $\\infty$.\n",
    "\n",
    "$\\large\\rightarrow$ But what values can $\\hat{y}$ take? What does this function even look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c16bdab38>]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot this function here:\n",
    "\n",
    "X = np.linspace(-10, 10, 300)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "plt.plot(X, 1/(1+np.exp(1)**(-X)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we fit a line to our dependent variable if its values are already stored as probabilities? We can use the inverse of the sigmoid function, and just set our regression equation equal to that. The inverse of the sigmoid function is called the **logit function**, and it looks like this:\n",
    "\n",
    "$\\large f(y) = \\ln\\left(\\frac{y}{1 - y}\\right)$. Notice that the domain of this function is $(0, 1)$.\n",
    "\n",
    "$\\hspace{110mm}$(Quick proof that logit and sigmoid are inverse functions:\n",
    "\n",
    "$\\hspace{170mm}x = \\frac{1}{1 + e^{-y}}$; <br/>\n",
    "$\\hspace{170mm}$so $1 + e^{-y} = \\frac{1}{x}$; <br/>\n",
    "$\\hspace{170mm}$so $e^{-y} = \\frac{1 - x}{x}$; <br/>\n",
    "$\\hspace{170mm}$so $-y = \\ln\\left(\\frac{1 - x}{x}\\right)$; <br/>\n",
    "$\\hspace{170mm}$so $y = \\ln\\left(\\frac{x}{1 - x}\\right)$.)\n",
    "\n",
    "Our regression equation will now look like this:\n",
    "\n",
    "$\\large\\ln\\left(\\frac{y}{1 - y}\\right) = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$.\n",
    "\n",
    "This equation is used for a **logistic regression**: Its characteristic link function is this logit function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ways to squeeze the results of a linear regression into the set (0, 1).\n",
    "\n",
    "But *this* function represents the **log-odds** of success (y = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression in Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/learn-env/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.ufunc size changed, may indicate binary incompatibility. Expected 192 from C header, got 216 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data = pd.read_csv('heart.csv')\n",
    "\n",
    "\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split our data into train and test.\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a logistic regression object with the 'liblinear' solver,\n",
    "# which is good for small datasets.\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "\n",
    "# Now fit it to the training data.\n",
    "\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call .predict() on the first row of our testing data.\n",
    "\n",
    "logreg.predict(X_test.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90433112, 0.09566888]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .predict() vs. .predict_proba()\n",
    "\n",
    "logreg.predict_proba(X_test.head(1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "179    0\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.868421052631579"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Regression\n",
    "\n",
    "Here's a different sort of regression equation:\n",
    "\n",
    "$\\large\\ln(y) = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$. The link function is simply $\\ln(y)$ and so we have:\n",
    "\n",
    "$\\large\\hat{y} = e^\\hat{L} = e^{\\beta_0 + ... + \\beta_nx_n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domain, or \"support\", for a Poisson distribution is {0, 1, 2, ... }. Can you see why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Regression in Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards = pd.read_csv('https://stats.idre.ucla.edu/stat/data/poisson_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_awards</th>\n",
       "      <th>prog</th>\n",
       "      <th>math</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  num_awards  prog  math\n",
       "0   45           0     3    41\n",
       "1  108           0     1    41\n",
       "2   15           0     3    44\n",
       "3   67           0     3    42\n",
       "4  153           0     3    40"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awards.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this dataset about?\n",
    "\n",
    "The data show the number of awards earned by students at one high school. 'Prog' is a coded version of the sort of program in which the student was enrolled and 'math' is a score on a math exam.\n",
    "\n",
    "Let's one-hot encode it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(categories='auto')\n",
    "\n",
    "ohe_new = ohe.fit_transform(awards['prog'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_dums = pd.concat([awards, pd.DataFrame(ohe_new.todense())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_awards</th>\n",
       "      <th>prog</th>\n",
       "      <th>math</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  num_awards  prog  math    0    1    2\n",
       "0   45           0     3    41  0.0  0.0  1.0\n",
       "1  108           0     1    41  1.0  0.0  0.0\n",
       "2   15           0     3    44  0.0  0.0  1.0\n",
       "3   67           0     3    42  0.0  0.0  1.0\n",
       "4  153           0     3    40  0.0  0.0  1.0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awards_dums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "//anaconda3/envs/learn-env/lib/python3.6/site-packages/numpy/core/fromnumeric.py:2389: FutureWarning: Method .ptp is deprecated and will be removed in a future version. Use numpy.ptp instead.\n",
      "  return ptp(axis=axis, out=out, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>num_awards</td>    <th>  No. Observations:  </th>  <td>   200</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   196</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th> <td>  1.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -182.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Wed, 25 Sep 2019</td> <th>  Deviance:          </th> <td>  189.45</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>11:02:39</td>     <th>  Pearson chi2:      </th>  <td>  212.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>5</td>        <th>  Covariance Type:   </th> <td>nonrobust</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -3.5719</td> <td>    0.459</td> <td>   -7.774</td> <td> 0.000</td> <td>   -4.472</td> <td>   -2.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>math</th>  <td>    0.0702</td> <td>    0.011</td> <td>    6.619</td> <td> 0.000</td> <td>    0.049</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>     <td>   -1.6752</td> <td>    0.289</td> <td>   -5.804</td> <td> 0.000</td> <td>   -2.241</td> <td>   -1.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>     <td>   -0.5913</td> <td>    0.248</td> <td>   -2.380</td> <td> 0.017</td> <td>   -1.078</td> <td>   -0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>     <td>   -1.3054</td> <td>    0.259</td> <td>   -5.040</td> <td> 0.000</td> <td>   -1.813</td> <td>   -0.798</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:             num_awards   No. Observations:                  200\n",
       "Model:                            GLM   Df Residuals:                      196\n",
       "Model Family:                 Poisson   Df Model:                            3\n",
       "Link Function:                    log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -182.75\n",
       "Date:                Wed, 25 Sep 2019   Deviance:                       189.45\n",
       "Time:                        11:02:39   Pearson chi2:                     212.\n",
       "No. Iterations:                     5   Covariance Type:             nonrobust\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -3.5719      0.459     -7.774      0.000      -4.472      -2.671\n",
       "math           0.0702      0.011      6.619      0.000       0.049       0.091\n",
       "0             -1.6752      0.289     -5.804      0.000      -2.241      -1.109\n",
       "1             -0.5913      0.248     -2.380      0.017      -1.078      -0.104\n",
       "2             -1.3054      0.259     -5.040      0.000      -1.813      -0.798\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a statsmodels summary here!\n",
    "\n",
    "X = sm.add_constant(awards_dums[['math', 0, 1, 2]])\n",
    "y = awards_dums['num_awards']\n",
    "poi_model = sm.GLM(y, X, sm.families.Poisson())\n",
    "poi_model.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.072722704342061"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpreting the results\n",
    "\n",
    "np.exp(0.0702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
