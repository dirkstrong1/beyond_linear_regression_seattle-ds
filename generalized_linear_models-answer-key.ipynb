{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generalized Linear Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear regressions have limitations.\n",
    "\n",
    "As it stands, the algorithm could generate a prediction *anywhere on the real number line*. This *may* be realistic, like if I'm predicting national surpluses/debts.\n",
    "\n",
    "But what if I'm predicting values of a variable that doesn't take, say, negative values, like temperature in Kelvin?\n",
    "\n",
    "What if I'm predicting values of a variable that takes only integer values, like the number of mouseclicks on my killer ds blog per minute?\n",
    "\n",
    "What if I'm predicting probabilities? Or something Boolean / Bernoullian?\n",
    "\n",
    "What if the shape of my errors changes as a function of the dependent variable?\n",
    "\n",
    "Am I stuck using linear regression? There's got to be a better way!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The strategy now is to *generalize* the notion of linear regression; regression will become a special case. In particular, we'll keep the idea of the regression best-fit line, but now **we'll allow the model to be constructed from the dependent variable through some (non-trivial) function of the linear predictor**. This function is standardly called the **link function**.\n",
    "\n",
    "Let's say we've constructed our best-fit line, i.e. our linear predictor, $\\hat{L} = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$.\n",
    "\n",
    "And now imagine applying a link function ... Check out Wikipedia's page on [Generalized Linear Models](https://en.wikipedia.org/wiki/Generalized_linear_model)!\n",
    "\n",
    "## Logistic Regression\n",
    "\n",
    "Consider the following transformation: <br/>\n",
    "$\\large\\hat{y} = \\Large\\frac{1}{1 + e^{-\\hat{L}}} \\large= \\Large\\frac{1}{1 + e^{-(\\beta_0 + ... + \\beta_nx_n)}}$. This is called the **sigmoid function**.\n",
    "\n",
    "We're imagining that $\\hat{L}$ can take any values between $-\\infty$ and $\\infty$.\n",
    "\n",
    "$\\large\\rightarrow$ But what values can $\\hat{y}$ take? What does this function even look like?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's plot this function here:\n",
    "\n",
    "X = np.linspace(-10, 10, 300)\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "Y = 1 / (1 + np.exp(-X))\n",
    "\n",
    "plt.plot(X, Y, 'r');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How do we fit a line to our dependent variable if its values are already stored as probabilities? We can use the inverse of the sigmoid function, and just set our regression equation equal to that. The inverse of the sigmoid function is called the **logit function**, and it looks like this:\n",
    "\n",
    "$\\large f(y) = \\ln\\left(\\frac{y}{1 - y}\\right)$. Notice that the domain of this function is $(0, 1)$.\n",
    "\n",
    "$\\hspace{110mm}$(Quick proof that logit and sigmoid are inverse functions:\n",
    "\n",
    "$\\hspace{170mm}x = \\frac{1}{1 + e^{-y}}$; <br/>\n",
    "$\\hspace{170mm}$so $1 + e^{-y} = \\frac{1}{x}$; <br/>\n",
    "$\\hspace{170mm}$so $e^{-y} = \\frac{1 - x}{x}$; <br/>\n",
    "$\\hspace{170mm}$so $-y = \\ln\\left(\\frac{1 - x}{x}\\right)$; <br/>\n",
    "$\\hspace{170mm}$so $y = \\ln\\left(\\frac{x}{1 - x}\\right)$.)\n",
    "\n",
    "Our regression equation will now look like this:\n",
    "\n",
    "$\\large\\ln\\left(\\frac{y}{1 - y}\\right) = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$.\n",
    "\n",
    "This equation is used for a **logistic regression**: Its characteristic link function is this logit function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are other ways to squeeze the results of a linear regression into the set (0, 1).\n",
    "\n",
    "But *this* function represents the **log-odds** of success (y = 1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression in Sci-Kit Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "data = pd.read_csv('../../Module-1/manipulating_data_with_pandas/heart.csv')\n",
    "\n",
    "\n",
    "X = data.drop('target', axis=1)\n",
    "y = data['target']\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's split our data into train and test.\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
       "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
       "                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n",
       "                   warm_start=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instantiate a logistic regression object with the 'liblinear' solver,\n",
    "# which is good for small datasets.\n",
    "\n",
    "logreg = LogisticRegression(solver='liblinear', multi_class='auto')\n",
    "\n",
    "# Now fit it to the training data.\n",
    "\n",
    "logreg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let's call .predict() on the first row of our testing data.\n",
    "\n",
    "first_test_row = X_test.head(1)\n",
    "logreg.predict(first_test_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.90433112, 0.09566888]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# .predict() vs. .predict_proba()\n",
    "\n",
    "logreg.predict_proba(first_test_row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Poisson Regression\n",
    "\n",
    "Here's a different sort of regression equation:\n",
    "\n",
    "$\\large\\ln(y) = \\beta_0 + \\beta_1x_1 + ... + \\beta_nx_n$. The link function is simply $\\ln(y)$ and so we have:\n",
    "\n",
    "$\\large\\hat{y} = e^\\hat{L} = e^{\\beta_0 + ... + \\beta_nx_n}$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The domain, or \"support\", for a Poisson distribution is {0, 1, 2, ... }. Can you see why?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Poisson Regression in Statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards = pd.read_csv('https://stats.idre.ucla.edu/stat/data/poisson_sim.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_awards</th>\n",
       "      <th>prog</th>\n",
       "      <th>math</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  num_awards  prog  math\n",
       "0   45           0     3    41\n",
       "1  108           0     1    41\n",
       "2   15           0     3    44\n",
       "3   67           0     3    42\n",
       "4  153           0     3    40"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awards.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is this dataset about?\n",
    "\n",
    "The data show the number of awards earned by students at one high school. 'Prog' is a coded version of the sort of program in which the student was enrolled and 'math' is a score on a math exam.\n",
    "\n",
    "Let's one-hot encode it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = OneHotEncoder(categories='auto')\n",
    "\n",
    "ohe_new = ohe.fit_transform(awards['prog'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "awards_dums = pd.concat([awards, pd.DataFrame(ohe_new.todense())], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>num_awards</th>\n",
       "      <th>prog</th>\n",
       "      <th>math</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>41</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>108</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>67</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>42</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>153</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    id  num_awards  prog  math    0    1    2\n",
       "0   45           0     3    41  0.0  0.0  1.0\n",
       "1  108           0     1    41  1.0  0.0  0.0\n",
       "2   15           0     3    44  0.0  0.0  1.0\n",
       "3   67           0     3    42  0.0  0.0  1.0\n",
       "4  153           0     3    40  0.0  0.0  1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "awards_dums.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Generalized Linear Model Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>     <td>num_awards</td>    <th>  No. Observations:  </th>  <td>   200</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>GLM</td>       <th>  Df Residuals:      </th>  <td>   196</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model Family:</th>        <td>Poisson</td>     <th>  Df Model:          </th>  <td>     3</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Link Function:</th>         <td>log</td>       <th>  Scale:             </th> <td>  1.0000</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>               <td>IRLS</td>       <th>  Log-Likelihood:    </th> <td> -182.75</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>           <td>Mon, 12 Aug 2019</td> <th>  Deviance:          </th> <td>  189.45</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>               <td>17:17:41</td>     <th>  Pearson chi2:      </th>  <td>  212.</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Iterations:</th>         <td>5</td>        <th>  Covariance Type:   </th> <td>nonrobust</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>   -3.5719</td> <td>    0.459</td> <td>   -7.774</td> <td> 0.000</td> <td>   -4.472</td> <td>   -2.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>math</th>  <td>    0.0702</td> <td>    0.011</td> <td>    6.619</td> <td> 0.000</td> <td>    0.049</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>0</th>     <td>   -1.6752</td> <td>    0.289</td> <td>   -5.804</td> <td> 0.000</td> <td>   -2.241</td> <td>   -1.109</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>1</th>     <td>   -0.5913</td> <td>    0.248</td> <td>   -2.380</td> <td> 0.017</td> <td>   -1.078</td> <td>   -0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>2</th>     <td>   -1.3054</td> <td>    0.259</td> <td>   -5.040</td> <td> 0.000</td> <td>   -1.813</td> <td>   -0.798</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                 Generalized Linear Model Regression Results                  \n",
       "==============================================================================\n",
       "Dep. Variable:             num_awards   No. Observations:                  200\n",
       "Model:                            GLM   Df Residuals:                      196\n",
       "Model Family:                 Poisson   Df Model:                            3\n",
       "Link Function:                    log   Scale:                          1.0000\n",
       "Method:                          IRLS   Log-Likelihood:                -182.75\n",
       "Date:                Mon, 12 Aug 2019   Deviance:                       189.45\n",
       "Time:                        17:17:41   Pearson chi2:                     212.\n",
       "No. Iterations:                     5   Covariance Type:             nonrobust\n",
       "==============================================================================\n",
       "                 coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const         -3.5719      0.459     -7.774      0.000      -4.472      -2.671\n",
       "math           0.0702      0.011      6.619      0.000       0.049       0.091\n",
       "0             -1.6752      0.289     -5.804      0.000      -2.241      -1.109\n",
       "1             -0.5913      0.248     -2.380      0.017      -1.078      -0.104\n",
       "2             -1.3054      0.259     -5.040      0.000      -1.813      -0.798\n",
       "==============================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get a statsmodels summary here!\n",
    "\n",
    "X = sm.add_constant(awards_dums[['math', 0, 1, 2]])\n",
    "y = awards_dums['num_awards']\n",
    "\n",
    "poi_model = sm.GLM(y, X, sm.families.Poisson())\n",
    "poi_model.fit().summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.072722704342061"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Interpreting the results\n",
    "\n",
    "np.exp(0.0702)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
